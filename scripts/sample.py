import argparse
import os
import torch
import torchvision
import numpy as np
from PIL import Image
from pathlib import Path
import datetime
import sys

sys.path.append(str(Path(__file__).resolve().parent.parent))

from ddpm.Unet import ControlPointUNet
from ddpm.diffusion import create_sampler


class BambooRestorer:
    """
    ç«¹ç®€æ¢å¤å™¨
    """

    def __init__(self, model_path, device='cuda', T=100):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.T = T
        self.model = self._load_model(model_path)

        # <<< æ ¸å¿ƒä¿®æ”¹ï¼šåˆ›å»ºå¹¶ä½¿ç”¨åœ¨ diffusion.py ä¸­å®šä¹‰çš„é‡‡æ ·å™¨ >>>
        self.sampler = create_sampler(self.model, T=self.T)

        print(f"ğŸ”¬ é€æ­¥æ¢å¤å™¨åˆå§‹åŒ–å®Œæˆï¼Œå°†åœ¨è®¾å¤‡ {self.device} ä¸Šè¿è¡Œ {self.T} æ­¥")

    def _load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ """
        print(f"â³ æ­£åœ¨ä» {model_path} åŠ è½½æ¨¡å‹...")
        try:
            checkpoint = torch.load(model_path, map_location=self.device)
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            raise

        # ä¼˜å…ˆä»æ£€æŸ¥ç‚¹ä¸­è·å–æ¨¡å‹å‚æ•°æ¥æ„å»ºæ¨¡å‹
        if 'args' in checkpoint:
            args = checkpoint['args']
            print("âœ… ä»æ£€æŸ¥ç‚¹ä¸­æ‰¾åˆ°'args'ï¼Œä½¿ç”¨ä¿å­˜çš„å‚æ•°æ„å»ºæ¨¡å‹ã€‚")
            model = ControlPointUNet(
                image_size=args.image_size,
                control_grid_size=(args.control_ny, args.control_nx)
                # å…¶ä»–å‚æ•°å¯ä»¥ä½¿ç”¨é»˜è®¤å€¼ï¼Œå› ä¸ºå®ƒä»¬ä¸»è¦å½±å“è®­ç»ƒ
            )
        else:
            print("âš ï¸ æ£€æŸ¥ç‚¹ä¸­æ²¡æœ‰æ‰¾åˆ°'args'ï¼Œè¯·ç¡®ä¿é»˜è®¤å‚æ•°ä¸è®­ç»ƒè®¾ç½®ä¸€è‡´!")
            model = ControlPointUNet()

        # åŠ è½½æ¨¡å‹æƒé‡
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)

        model.to(self.device)
        model.eval()
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸå¹¶ç§»è‡³ {self.device}")
        return model

    def load_image(self, image_path, target_size=(320, 32)):
        """åŠ è½½å¹¶é¢„å¤„ç†å•å¼ ç«¹ç®€å›¾åƒ """
        try:
            pil_image = Image.open(image_path).convert('RGB')
            # PILçš„resizeéœ€è¦(å®½åº¦, é«˜åº¦)
            pil_image = pil_image.resize((target_size[1], target_size[0]), Image.LANCZOS)
            img_array = np.array(pil_image, dtype=np.float32) / 255.0
            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
            return img_tensor.to(self.device)
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½å›¾åƒ {image_path}: {e}")
            return None

    def restore_single_image(self, deformed_image_tensor):
        """
        æ¢å¤å•å¼ ç«¹ç®€å›¾åƒ
        """
        with torch.no_grad():
            restored_tensor, history = self.sampler(deformed_image_tensor)
        return restored_tensor, history

    @staticmethod
    def _save_restoration_results(deformed_tensor, restored_tensor, history, image_name, output_dir):
        restored_dir = output_dir / "restored"
        comparisons_dir = output_dir / "comparisons"
        history_dir = output_dir / "history"
        for dir_path in [restored_dir, comparisons_dir, history_dir]:
            dir_path.mkdir(exist_ok=True, parents=True)

        torchvision.utils.save_image(restored_tensor, restored_dir / f"{image_name}_restored.png")

        comparison_image = torch.cat([deformed_tensor, restored_tensor], dim=2)
        torchvision.utils.save_image(comparison_image, comparisons_dir / f"{image_name}_comparison.png")

        if history:
            num_frames = len(history)
            if num_frames > 10:
                indices = np.linspace(0, num_frames - 1, 10, dtype=int)
                sampled_history = [history[i] for i in indices]
            else:
                sampled_history = history
            history_image = torch.cat([torch.clamp(frame.squeeze(0), 0, 1) for frame in sampled_history], dim=2)
            torchvision.utils.save_image(history_image, history_dir / f"{image_name}_process.png")


def main():
    parser = argparse.ArgumentParser(description='ç«¹ç®€æ¢å¤é‡‡æ ·å™¨ - é€æ­¥æ¢å¤ç‰ˆ')

    parser.add_argument('--model_path', type=str, required=True, help='è®­ç»ƒå¥½çš„â€œé€æ­¥æ¢å¤â€æ¨¡å‹è·¯å¾„ (.ptæ–‡ä»¶)')
    parser.add_argument('--input_path', type=str, required=True, help='è¾“å…¥å›¾åƒè·¯å¾„æˆ–åŒ…å«å›¾åƒçš„ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='./output', help='è¾“å‡ºç»“æœçš„æ ¹ç›®å½•')
    parser.add_argument('--device', type=str, default='cuda', choices=['cuda', 'cpu'], help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--T', type=int, default=100, help='æ¢å¤çš„æ€»æ­¥æ•°ï¼Œå¿…é¡»ä¸æ¨¡å‹è®­ç»ƒæ—¶çš„Tä¸€è‡´')
    parser.add_argument('--image_size', type=int, nargs=2, default=[320, 32],
                        help='å›¾åƒå°ºå¯¸ [H, W]ï¼Œå¿…é¡»ä¸æ¨¡å‹è®­ç»ƒæ—¶ä¸€è‡´')

    args = parser.parse_args()

    input_path = Path(args.input_path)
    if not input_path.exists():
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}");
        return

    model_path = Path(args.model_path)
    if not model_path.exists():
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}");
        return

    restorer = BambooRestorer(model_path=args.model_path, device=args.device, T=args.T)

    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(args.output_dir) / f"restoration_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“‚ ç»“æœå°†ä¿å­˜åœ¨: {output_dir}")

    if input_path.is_file():
        image_paths = [input_path]
    else:
        valid_extensions = ['.png', '.jpg', '.jpeg']
        image_paths = [p for p in input_path.glob('**/*') if p.suffix.lower() in valid_extensions]

    if not image_paths:
        print("âŒ åœ¨æŒ‡å®šè·¯å¾„ä¸‹æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶ã€‚");
        return

    print(f"æ‰¾åˆ°äº† {len(image_paths)} å¼ å¾…å¤„ç†çš„å›¾åƒã€‚")

    for image_path in image_paths:
        image_name = image_path.stem
        print(f"\n--- æ­£åœ¨å¤„ç†: {image_name} ---")

        deformed_tensor = restorer.load_image(image_path, tuple(args.image_size))
        if deformed_tensor is None:
            continue

        try:
            restored_tensor, history = restorer.restore_single_image(deformed_tensor)
            BambooRestorer._save_restoration_results(
                deformed_tensor.squeeze(0),
                restored_tensor.squeeze(0),
                history,
                image_name,
                output_dir
            )
            print(f"âœ… å¤„ç†å®Œæˆ: {image_name}")

        except Exception as e:
            import traceback
            print(f"âŒ å¤„ç†å¤±è´¥ {image_name}: {e}")
            traceback.print_exc()

    print(f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ! ç»“æœå·²ä¿å­˜åœ¨: {output_dir}")


if __name__ == "__main__":
    main()
