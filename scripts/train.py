import argparse
import datetime
import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
from pathlib import Path
from tqdm import tqdm

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from Unet import ControlPointUNet
from diffusion import CreepDiffusionTrainer
from forward import CreepDeformationEngine


class BambooSlipsDataset(Dataset):
    """ç«¹ç®€æ•°æ®é›†"""

    def __init__(self, root_dir, transform=None, image_size=(640, 64)):
        self.root_dir = root_dir
        self.transform = transform
        self.image_size = image_size

        # æ”¯æŒå¤šç§å›¾åƒæ ¼å¼
        valid_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']
        self.img_paths = []

        for ext in valid_extensions:
            self.img_paths.extend(
                [os.path.join(root_dir, f) for f in os.listdir(root_dir)
                 if f.lower().endswith(ext)]
            )

        print(f"ğŸ“¦ æ‰¾åˆ° {len(self.img_paths)} å¼ ç«¹ç®€å›¾åƒ")

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]

        try:
            # ä½¿ç”¨PILè¯»å–å›¾åƒ
            img = Image.open(img_path).convert('RGB')

            # è°ƒæ•´åˆ°ç«¹ç®€å°ºå¯¸ (640, 64) -> (W, H)
            img = img.resize((self.image_size[1], self.image_size[0]), Image.LANCZOS)

            if self.transform:
                img_tensor = self.transform(img)
            else:
                # æ‰‹åŠ¨è½¬æ¢ä¸ºtensor
                img_array = np.array(img, dtype=np.float32) / 255.0
                img_tensor = torch.from_numpy(img_array).permute(2, 0, 1)

        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ {img_path}: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„é»‘è‰²å›¾åƒ
            img_tensor = torch.zeros(3, self.image_size[0], self.image_size[1])

        return img_tensor


class TrainingLogger:
    """ç®€åŒ–çš„è®­ç»ƒæ—¥å¿—è®°å½•å™¨"""

    def __init__(self, log_dir):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # å­ç›®å½•
        self.checkpoints_dir = self.log_dir / "checkpoints"
        self.visualizations_dir = self.log_dir / "visualizations"

        for dir_path in [self.checkpoints_dir, self.visualizations_dir]:
            dir_path.mkdir(exist_ok=True)

        # æ—¥å¿—æ–‡ä»¶
        self.log_file = self.log_dir / "training.log"
        self.metrics_file = self.log_dir / "metrics.csv"

        # è®­ç»ƒæŒ‡æ ‡
        self.steps = []
        self.losses = []

        # åˆå§‹åŒ–æ–‡ä»¶
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ‹ ç«¹ç®€è •å˜æ‰©æ•£æ¨¡å‹è®­ç»ƒå¼€å§‹\n")
            f.write(f"æ—¶é—´: {datetime.datetime.now()}\n")
            f.write("=" * 50 + "\n\n")

        with open(self.metrics_file, 'w', encoding='utf-8') as f:
            f.write("step,loss\n")

    def log(self, message, step=None):
        """è®°å½•æ—¥å¿—"""
        if step is not None:
            message = f"[æ­¥éª¤ {step}] {message}"

        print(message)

        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(message + "\n")

    def log_metrics(self, step, loss):
        """è®°å½•è®­ç»ƒæŒ‡æ ‡"""
        self.steps.append(step)
        self.losses.append(loss)

        # ä¿å­˜åˆ°CSV
        with open(self.metrics_file, 'a', encoding='utf-8') as f:
            f.write(f"{step},{loss}\n")

    def save_training_visualization(self, original_batch, deformed_batch, step, max_samples=4):
        """ä¿å­˜è®­ç»ƒå¯è§†åŒ– - åªæ˜¾ç¤ºåŸå›¾vså˜å½¢å›¾"""
        batch_size = min(original_batch.size(0), max_samples)

        fig, axes = plt.subplots(2, batch_size, figsize=(4 * batch_size, 8))
        if batch_size == 1:
            axes = axes.reshape(-1, 1)

        for i in range(batch_size):
            # åŸå§‹å›¾åƒ
            orig_img = original_batch[i].permute(1, 2, 0).cpu().numpy()
            orig_img = np.clip(orig_img, 0, 1)
            axes[0, i].imshow(orig_img)
            axes[0, i].set_title(f'åŸå§‹ç«¹ç®€ {i + 1}')
            axes[0, i].axis('off')

            # å˜å½¢å›¾åƒ
            deformed_img = deformed_batch[i].permute(1, 2, 0).cpu().numpy()
            deformed_img = np.clip(deformed_img, 0, 1)
            axes[1, i].imshow(deformed_img)
            axes[1, i].set_title(f'ç‰©ç†å˜å½¢ {i + 1}')
            axes[1, i].axis('off')

        plt.tight_layout()
        plt.savefig(self.visualizations_dir / f"training_step_{step}.png",
                    dpi=150, bbox_inches='tight')
        plt.close()

    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        if len(self.steps) == 0:
            return

        fig, axes = plt.subplots(1, 2, figsize=(12, 5))

        # æŸå¤±æ›²çº¿
        axes[0].plot(self.steps, self.losses, 'b-', label='è®­ç»ƒæŸå¤±')
        axes[0].set_xlabel('è®­ç»ƒæ­¥æ•°')
        axes[0].set_ylabel('æŸå¤±å€¼')
        axes[0].set_title('è®­ç»ƒæŸå¤±æ›²çº¿')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # æŸå¤±åˆ†å¸ƒ
        if len(self.losses) > 10:
            axes[1].hist(self.losses[-100:], bins=20, alpha=0.7, label='æœ€è¿‘100æ­¥')
            axes[1].set_xlabel('æŸå¤±å€¼')
            axes[1].set_ylabel('é¢‘æ¬¡')
            axes[1].set_title('æŸå¤±åˆ†å¸ƒ')
            axes[1].legend()
            axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.log_dir / "training_curves.png", dpi=150, bbox_inches='tight')
        plt.close()


def create_model(args):
    """åˆ›å»ºæ¨¡å‹"""
    # åˆ›å»ºU-Netæ¨¡å‹ - ä½¿ç”¨ç®€åŒ–çš„æ§åˆ¶ç‚¹ç½‘æ ¼
    model = ControlPointUNet(
        img_channels=args.img_channels,
        base_channels=args.base_channels,
        control_grid_size=(args.control_nx, args.control_ny),  # (4, 2)
        channel_mults=args.channel_mults,
        num_res_blocks=args.num_res_blocks,
        time_emb_dim=args.time_emb_dim,
        time_emb_scale=args.time_emb_scale,
        num_classes=args.num_classes if args.num_classes > 0 else None,
        activation=torch.nn.functional.relu,
        dropout=args.dropout,
        attention_resolutions=args.attention_resolutions,
        norm=args.norm,
        num_groups=args.num_groups,
        max_displacement=args.max_displacement,
        image_size=args.image_size,
    )

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = CreepDiffusionTrainer(
        model=model,
        beta_1=args.beta_1,
        beta_T=args.beta_T,
        T=args.T,
        image_size=args.image_size,
        control_grid_size=(args.control_nx, args.control_ny),
        # ç‰©ç†å‚æ•°
        fiber_elongation_factor=args.fiber_elongation_factor,
        force_coupling_strength=args.force_coupling_strength,
        moisture_diffusion_coeff=args.moisture_diffusion_coeff,
        em_modulus=args.em_modulus,
        viscosity=args.viscosity,
        time_step=args.time_step,
        max_physics_iterations=args.max_physics_iterations,
        convergence_threshold=args.convergence_threshold,
        boundary_factor=args.boundary_factor,
        inertia_factor=args.inertia_factor,  # æ–°å¢åŠ¨é‡å‚æ•°
    )

    return model, trainer


def simple_evaluate_model(model, trainer, test_batch, device):
    """ç®€å•çš„æ¨¡å‹è¯„ä¼° - åªè®¡ç®—çœŸå®æŸå¤±"""
    model.eval()
    with torch.no_grad():
        # è®¡ç®—è®­ç»ƒæŸå¤±
        loss_batch = trainer(test_batch)
        avg_loss = loss_batch.mean().item()

    model.train()
    return avg_loss


def train_model(args):
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(args.output_dir) / f"creep_diffusion_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)

    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = TrainingLogger(output_dir)
    logger.log(f"ğŸ‹ å¼€å§‹è®­ç»ƒç«¹ç®€è •å˜æ‰©æ•£æ¨¡å‹")
    logger.log(f"è¾“å‡ºç›®å½•: {output_dir}")

    # æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])

    # è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†ç»“æ„
    dataset_root = Path(args.dataset_root)
    train_dir = dataset_root / "train"
    test_dir = dataset_root / "test"

    # æ£€æŸ¥æ•°æ®é›†ç»“æ„
    if train_dir.exists() and test_dir.exists():
        logger.log(f"ğŸ“‚ æ£€æµ‹åˆ°æ ‡å‡†æ•°æ®é›†ç»“æ„:")
        logger.log(f"   è®­ç»ƒé›†: {train_dir}")
        logger.log(f"   æµ‹è¯•é›†: {test_dir}")

        # åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†
        train_dataset = BambooSlipsDataset(
            root_dir=str(train_dir),
            transform=transform,
            image_size=args.image_size
        )

        test_dataset = BambooSlipsDataset(
            root_dir=str(test_dir),
            transform=transform,
            image_size=args.image_size
        )

        logger.log(f"ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
        logger.log(f"ğŸ“Š æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")

    else:
        # å¦‚æœæ²¡æœ‰æ ‡å‡†ç»“æ„ï¼Œå‡è®¾æ•´ä¸ªç›®å½•å°±æ˜¯è®­ç»ƒæ•°æ®
        logger.log(f"ğŸ“‚ ä½¿ç”¨å•ä¸€æ•°æ®ç›®å½•: {dataset_root}")
        train_dataset = BambooSlipsDataset(
            root_dir=str(dataset_root),
            transform=transform,
            image_size=args.image_size
        )
        test_dataset = None
        logger.log(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(train_dataset)}")

    # æ•°æ®åŠ è½½å™¨
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
        drop_last=True
    )

    # æµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºéªŒè¯ï¼‰
    test_dataloader = None
    if test_dataset is not None:
        test_dataloader = DataLoader(
            test_dataset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=args.num_workers,
            pin_memory=True,
            drop_last=False
        )

    logger.log(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    logger.log(f"ğŸ“Š è®­ç»ƒæ‰¹æ¬¡æ•°é‡: {len(train_dataloader)}")
    if test_dataloader:
        logger.log(f"ğŸ“Š æµ‹è¯•æ‰¹æ¬¡æ•°é‡: {len(test_dataloader)}")

    # åˆ›å»ºæ¨¡å‹
    model, trainer = create_model(args)
    model.to(device)
    trainer.to(device)

    # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    logger.log(f"ğŸ”§ æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    logger.log(f"ğŸ”§ å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay,
        betas=(args.beta1, args.beta2)
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=args.num_epochs,
        eta_min=args.lr * 0.1
    )

    # å¼€å§‹è®­ç»ƒ
    global_step = 0
    best_loss = float('inf')

    logger.log(f"ğŸš€ å¼€å§‹è®­ç»ƒ - æ€»è½®æ•°: {args.num_epochs}")

    for epoch in range(args.num_epochs):
        model.train()
        trainer.train()

        epoch_loss = 0
        num_batches = 0

        # è¿›åº¦æ¡
        pbar = tqdm(train_dataloader, desc=f"Epoch {epoch + 1}/{args.num_epochs}")

        for batch_idx, batch in enumerate(pbar):
            batch = batch.to(device)

            # æ¢¯åº¦æ¸…é›¶
            optimizer.zero_grad()

            # å‰å‘ä¼ æ’­ - æ ¸å¿ƒè®­ç»ƒæ­¥éª¤
            loss_batch = trainer(batch)
            loss = loss_batch.mean()

            # åå‘ä¼ æ’­
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)

            # æ›´æ–°å‚æ•°
            optimizer.step()

            # ç»Ÿè®¡
            epoch_loss += loss.item()
            num_batches += 1
            global_step += 1

            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'lr': f'{scheduler.get_last_lr()[0]:.2e}'
            })

            # è®°å½•æŒ‡æ ‡
            if global_step % args.log_interval == 0:
                logger.log_metrics(global_step, loss.item())

            # ä¿å­˜å¯è§†åŒ–
            if global_step % args.sample_interval == 0:
                logger.log(f"ğŸ’¾ ä¿å­˜å¯è§†åŒ–æ ·æœ¬ - æ­¥éª¤ {global_step}")

                # è·å–è¯„ä¼°ç”¨çš„æ‰¹æ¬¡
                if test_dataloader is not None:
                    eval_batch = next(iter(test_dataloader))[:4].to(device)
                else:
                    eval_batch = batch[:4]

                # è¯„ä¼°æ¨¡å‹
                avg_loss = simple_evaluate_model(model, trainer, eval_batch, device)
                logger.log(f"ğŸ“Š è¯„ä¼°æŸå¤±: {avg_loss:.4f}")

                # ç”Ÿæˆå˜å½¢æ ·æœ¬ç”¨äºå¯è§†åŒ–
                model.eval()
                with torch.no_grad():
                    # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ ·æœ¬
                    vis_batch_size = min(4, eval_batch.size(0))

                    # éšæœºé€‰æ‹©å˜å½¢ç¨‹åº¦
                    t_vis = torch.randint(1, trainer.T + 1, (vis_batch_size,), device=device)

                    # ç”Ÿæˆå˜å½¢æ ·æœ¬
                    deformed_samples = []
                    for i in range(vis_batch_size):
                        try:
                            # é‡ç½®ç‰©ç†å¼•æ“çŠ¶æ€
                            trainer.forward_trainer.creep_engine.reset_control_state()
                            # ç”Ÿæˆç‰©ç†å˜å½¢
                            x_t, _ = trainer.forward_trainer.forward_step_by_step(
                                eval_batch[i:i + 1], t_vis[i].item()
                            )

                            # æ£€æŸ¥è¿”å›çš„tensoræ˜¯å¦æœ‰æ•ˆ
                            if x_t.size(0) > 0:
                                deformed_samples.append(x_t[0])
                            else:
                                logger.log(f"âš ï¸ è­¦å‘Š: ç¬¬{i}ä¸ªæ ·æœ¬å˜å½¢å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾")
                                deformed_samples.append(eval_batch[i])

                        except Exception as e:
                            logger.log(f"âš ï¸ è­¦å‘Š: ç¬¬{i}ä¸ªæ ·æœ¬å˜å½¢å‡ºé”™: {e}")
                            # ä½¿ç”¨åŸå›¾ä½œä¸ºfallback
                            deformed_samples.append(eval_batch[i])

                    if deformed_samples:
                        deformed_batch = torch.stack(deformed_samples)
                        vis_original = eval_batch[:vis_batch_size]

                        # ä¿å­˜å¯è§†åŒ–ï¼ˆåŸå›¾ vs å˜å½¢å›¾ï¼‰
                        logger.save_training_visualization(
                            vis_original, deformed_batch, global_step
                        )
                    else:
                        logger.log("âš ï¸ è­¦å‘Š: æ— æ³•ç”Ÿæˆå¯è§†åŒ–æ ·æœ¬")

                model.train()

            # ä¿å­˜æ£€æŸ¥ç‚¹
            if global_step % args.save_interval == 0:
                checkpoint_path = logger.checkpoints_dir / f"checkpoint_step_{global_step}.pt"
                torch.save({
                    'epoch': epoch,
                    'global_step': global_step,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'loss': loss.item(),
                    'args': args,
                }, checkpoint_path)

                logger.log(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_epoch_loss = epoch_loss / num_batches

        # æ¯ä¸ªepochç»“æŸåè¯„ä¼°
        if test_dataloader is not None:
            model.eval()
            test_loss = 0
            test_batches = 0

            with torch.no_grad():
                for test_batch in test_dataloader:
                    test_batch = test_batch.to(device)
                    test_loss_batch = trainer(test_batch)
                    test_loss += test_loss_batch.mean().item()
                    test_batches += 1

            avg_test_loss = test_loss / test_batches
            logger.log(f"ğŸ“Š Epoch {epoch + 1} - è®­ç»ƒæŸå¤±: {avg_epoch_loss:.4f}, æµ‹è¯•æŸå¤±: {avg_test_loss:.4f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_test_loss < best_loss:
                best_loss = avg_test_loss
                best_model_path = logger.checkpoints_dir / "best_model.pt"
                torch.save({
                    'epoch': epoch,
                    'global_step': global_step,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'train_loss': avg_epoch_loss,
                    'test_loss': best_loss,
                    'args': args,
                }, best_model_path)

                logger.log(f"ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹! æµ‹è¯•æŸå¤±: {best_loss:.4f}")

            model.train()
        else:
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_epoch_loss < best_loss:
                best_loss = avg_epoch_loss
                best_model_path = logger.checkpoints_dir / "best_model.pt"
                torch.save({
                    'epoch': epoch,
                    'global_step': global_step,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'loss': best_loss,
                    'args': args,
                }, best_model_path)

                logger.log(f"ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹! æŸå¤±: {best_loss:.4f}")

            logger.log(f"ğŸ“Š Epoch {epoch + 1} å®Œæˆ - å¹³å‡æŸå¤±: {avg_epoch_loss:.4f}")

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        if (epoch + 1) % args.plot_interval == 0:
            logger.plot_training_curves()

    # è®­ç»ƒå®Œæˆ
    logger.log("è®­ç»ƒå®Œæˆ!")
    logger.log(f"æœ€ä½³æŸå¤±: {best_loss:.4f}")
    logger.plot_training_curves()

    return model, trainer


def main():
    parser = argparse.ArgumentParser(description='ç«¹ç®€è •å˜æ‰©æ•£æ¨¡å‹è®­ç»ƒ')

    # æ•°æ®å‚æ•°
    parser.add_argument('--dataset_root', type=str, required=True,
                        help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./outputs',
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--image_size', type=int, nargs=2, default=[640, 64],
                        help='å›¾åƒå°ºå¯¸ [H, W]')
    parser.add_argument('--img_channels', type=int, default=3,
                        help='å›¾åƒé€šé“æ•°')

    # è®­ç»ƒå‚æ•°
    parser.add_argument('--num_epochs', type=int, default=20,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=8,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=2e-4,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                        help='æƒé‡è¡°å‡')
    parser.add_argument('--beta1', type=float, default=0.9,
                        help='Adam beta1')
    parser.add_argument('--beta2', type=float, default=0.999,
                        help='Adam beta2')
    parser.add_argument('--grad_clip', type=float, default=1.0,
                        help='æ¢¯åº¦è£å‰ª')
    parser.add_argument('--num_workers', type=int, default=4,
                        help='æ•°æ®åŠ è½½å™¨å·¥ä½œçº¿ç¨‹æ•°')

    # æ¨¡å‹å‚æ•°
    parser.add_argument('--base_channels', type=int, default=64,
                        help='åŸºç¡€é€šé“æ•°')
    parser.add_argument('--channel_mults', type=int, nargs='+', default=[1, 2, 4, 8],
                        help='é€šé“å€æ•°')
    parser.add_argument('--num_res_blocks', type=int, default=2,
                        help='æ®‹å·®å—æ•°é‡')
    parser.add_argument('--time_emb_dim', type=int, default=256,
                        help='æ—¶é—´åµŒå…¥ç»´åº¦')
    parser.add_argument('--time_emb_scale', type=float, default=1.0,
                        help='æ—¶é—´åµŒå…¥ç¼©æ”¾')
    parser.add_argument('--num_classes', type=int, default=0,
                        help='ç±»åˆ«æ•°é‡')
    parser.add_argument('--dropout', type=float, default=0.2,
                        help='Dropoutç‡')
    parser.add_argument('--attention_resolutions', type=int, nargs='+', default=[1, 2],
                        help='æ³¨æ„åŠ›åˆ†è¾¨ç‡')
    parser.add_argument('--norm', type=str, default='gn',
                        help='å½’ä¸€åŒ–ç±»å‹')
    parser.add_argument('--num_groups', type=int, default=32,
                        help='GroupNormç»„æ•°')
    parser.add_argument('--max_displacement', type=float, default=50.0,
                        help='æœ€å¤§ä½ç§»')

    # æ§åˆ¶ç‚¹å‚æ•°
    parser.add_argument('--control_nx', type=int, default=16,
                        help='æ§åˆ¶ç‚¹Xæ–¹å‘æ•°é‡')
    parser.add_argument('--control_ny', type=int, default=4,
                        help='æ§åˆ¶ç‚¹Yæ–¹å‘æ•°é‡')

    # æ‰©æ•£å‚æ•°
    parser.add_argument('--beta_1', type=float, default=1e-4,
                        help='æ‰©æ•£beta_1')
    parser.add_argument('--beta_T', type=float, default=0.02,
                        help='æ‰©æ•£beta_T')
    parser.add_argument('--T', type=int, default=50,
                        help='æ‰©æ•£æ­¥æ•°')

    # ç‰©ç†å‚æ•°
    parser.add_argument('--fiber_elongation_factor', type=float, default=0.1,
                        help='çº¤ç»´ä¼¸é•¿å› å­')
    parser.add_argument('--force_coupling_strength', type=float, default=0.3,
                        help='åŠ›è€¦åˆå¼ºåº¦')
    parser.add_argument('--moisture_diffusion_coeff', type=float, default=0.05,
                        help='æ°´åˆ†æ‰©æ•£ç³»æ•°')
    parser.add_argument('--em_modulus', type=float, default=0.6,
                        help='å¼¹æ€§æ¨¡é‡')
    parser.add_argument('--viscosity', type=float, default=8.0,
                        help='é»æ€§ç³»æ•°')
    parser.add_argument('--time_step', type=float, default=1.0,
                        help='æ—¶é—´æ­¥é•¿')
    parser.add_argument('--max_physics_iterations', type=int, default=25,
                        help='æœ€å¤§ç‰©ç†è¿­ä»£æ¬¡æ•°')
    parser.add_argument('--convergence_threshold', type=float, default=0.01,
                        help='æ”¶æ•›é˜ˆå€¼')
    parser.add_argument('--boundary_factor', type=float, default=0.6,
                        help='è¾¹ç•Œå› å­')
    # --- æ–°å¢ç‰©ç†å‚æ•° ---
    parser.add_argument('--inertia_factor', type=float, default=0.7,
                        help='æƒ¯æ€§å› å­ï¼Œæ§åˆ¶å˜å½¢é€Ÿåº¦çš„è®°å¿†æ•ˆåº” (0-1)')

    # æ—¥å¿—å‚æ•°
    parser.add_argument('--log_interval', type=int, default=10,
                        help='æ—¥å¿—è®°å½•é—´éš”')
    parser.add_argument('--sample_interval', type=int, default=500,
                        help='æ ·æœ¬ä¿å­˜é—´éš”')
    parser.add_argument('--save_interval', type=int, default=2000,
                        help='æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”')
    parser.add_argument('--plot_interval', type=int, default=10,
                        help='ç»˜å›¾é—´éš”')

    args = parser.parse_args()

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)

    # å¼€å§‹è®­ç»ƒ
    model, trainer = train_model(args)

    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")


if __name__ == '__main__':
    main()
