import argparse
import datetime
import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
from pathlib import Path
from tqdm import tqdm

from ddpm.Unet import ControlPointUNet
from ddpm.diffusion import CreepDiffusionTrainer, create_trainer


class BambooSlipsDataset(Dataset):
    """ç«¹ç®€æ•°æ®é›†"""

    def __init__(self, root_dir, transform=None, image_size=(320, 32)):
        self.root_dir = root_dir
        self.transform = transform
        self.image_size = image_size
        valid_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']
        self.img_paths = []
        for ext in valid_extensions:
            self.img_paths.extend(
                [os.path.join(root_dir, f) for f in os.listdir(root_dir)
                 if f.lower().endswith(ext)]
            )
        print(f"ğŸ“¦ æ‰¾åˆ° {len(self.img_paths)} å¼ ç«¹ç®€å›¾åƒ")

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        try:
            img = Image.open(img_path).convert('RGB')
            img = img.resize((self.image_size[1], self.image_size[0]), Image.LANCZOS)
            if self.transform:
                img_tensor = self.transform(img)
            else:
                img_array = np.array(img, dtype=np.float32) / 255.0
                img_tensor = torch.from_numpy(img_array).permute(2, 0, 1)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ {img_path}: {e}")
            img_tensor = torch.zeros(3, self.image_size[0], self.image_size[1])
        return img_tensor


class TrainingLogger:
    """ç®€åŒ–çš„è®­ç»ƒæ—¥å¿—è®°å½•å™¨"""

    def __init__(self, log_dir):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self.checkpoints_dir = self.log_dir / "checkpoints"
        self.visualizations_dir = self.log_dir / "visualizations"
        for dir_path in [self.checkpoints_dir, self.visualizations_dir]:
            dir_path.mkdir(exist_ok=True)
        self.log_file = self.log_dir / "training.log"
        self.metrics_file = self.log_dir / "metrics.csv"
        self.steps = []
        self.losses = []
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ‹ ç«¹ç®€è •å˜æ‰©æ•£æ¨¡å‹è®­ç»ƒå¼€å§‹\n")
            f.write(f"æ—¶é—´: {datetime.datetime.now()}\n")
            f.write("=" * 50 + "\n\n")
        with open(self.metrics_file, 'w', encoding='utf-8') as f:
            f.write("step,loss\n")

    def log(self, message, step=None):
        if step is not None:
            message = f"[æ­¥éª¤ {step}] {message}"
        print(message)
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(message + "\n")

    def log_metrics(self, step, loss):
        self.steps.append(step)
        self.losses.append(loss)
        with open(self.metrics_file, 'a', encoding='utf-8') as f:
            f.write(f"{step},{loss}\n")

    def plot_training_curves(self):
        if not self.steps: return
        plt.figure(figsize=(10, 5))
        plt.plot(self.steps, self.losses, 'b-', label='è®­ç»ƒæŸå¤±')
        plt.xlabel('è®­ç»ƒæ­¥æ•°')
        plt.ylabel('æŸå¤±å€¼')
        plt.title('è®­ç»ƒæŸå¤±æ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.savefig(self.log_dir / "training_curves.png", dpi=150)
        plt.close()


def train_model(args):
    """ä¸»è®­ç»ƒå‡½æ•°"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(args.output_dir) / f"creep_diffusion_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)

    logger = TrainingLogger(output_dir)
    logger.log(f"ğŸ‹ å¼€å§‹ä¸º 'é€æ­¥æ¢å¤' æ¨¡å‹è¿›è¡Œè®­ç»ƒ")
    logger.log(f"è¾“å‡ºç›®å½•: {output_dir}")
    logger.log(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    transform = transforms.Compose([transforms.ToTensor()])

    train_dataset = BambooSlipsDataset(
        root_dir=str(Path(args.dataset_root) / "train"),
        transform=transform,
        image_size=args.image_size
    )
    test_dataset = BambooSlipsDataset(
        root_dir=str(Path(args.dataset_root) / "test"),
        transform=transform,
        image_size=args.image_size
    )

    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers,
                                  pin_memory=True, drop_last=True)
    test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers,
                                 pin_memory=True)

    logger.log(f"ğŸ“Š è®­ç»ƒé›†: {len(train_dataset)} | æµ‹è¯•é›†: {len(test_dataset)} | æ‰¹æ¬¡å¤§å°: {args.batch_size}")

    # åˆ›å»ºæ¨¡å‹å’Œæˆ‘ä»¬æ–°çš„â€œé€æ­¥æ¢å¤â€è®­ç»ƒå™¨
    model = ControlPointUNet(image_size=args.image_size, control_grid_size=(args.control_ny, args.control_nx))

    # ç‰©ç†å‚æ•°å­—å…¸
    physics_params = {
        'fiber_elongation_factor': args.fiber_elongation_factor,
        'force_coupling_strength': args.force_coupling_strength,
        'moisture_diffusion_coeff': args.moisture_diffusion_coeff,
        'inertia_factor': args.inertia_factor,
    }

    trainer = create_trainer(model, T=args.T, image_size=args.image_size, **physics_params)

    model.to(device)
    trainer.to(device)

    logger.log(f"ğŸ”§ æ¨¡å‹å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.num_epochs, eta_min=args.lr * 0.1)

    global_step = 0
    best_loss = float('inf')

    logger.log(f"ğŸš€ å¼€å§‹è®­ç»ƒ - æ€»è½®æ•°: {args.num_epochs}")

    for epoch in range(args.num_epochs):
        model.train()
        epoch_loss = 0.0
        pbar = tqdm(train_dataloader, desc=f"Epoch {epoch + 1}/{args.num_epochs}")

        for batch in pbar:
            batch = batch.to(device)
            optimizer.zero_grad()

            loss = trainer(batch).mean()

            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            optimizer.step()

            epoch_loss += loss.item()
            global_step += 1
            pbar.set_postfix({'loss': f'{loss.item():.6f}', 'lr': f'{scheduler.get_last_lr()[0]:.2e}'})

            if global_step % args.log_interval == 0:
                logger.log_metrics(global_step, loss.item())

        scheduler.step()
        avg_epoch_loss = epoch_loss / len(train_dataloader)

        # æ¯ä¸ª epoch ç»“æŸååœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        model.eval()
        test_loss = 0.0
        with torch.no_grad():
            for test_batch in test_dataloader:
                test_batch = test_batch.to(device)
                test_loss += trainer(test_batch).mean().item()
        avg_test_loss = test_loss / len(test_dataloader)

        logger.log(f"ğŸ“Š Epoch {epoch + 1} - è®­ç»ƒæŸå¤±: {avg_epoch_loss:.6f}, æµ‹è¯•æŸå¤±: {avg_test_loss:.6f}")

        if avg_test_loss < best_loss:
            best_loss = avg_test_loss
            best_model_path = logger.checkpoints_dir / "best_model.pt"
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'test_loss': best_loss,
                'args': args,
            }, best_model_path)
            logger.log(f"ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹! æµ‹è¯•æŸå¤±: {best_loss:.6f}")

    logger.log("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    logger.plot_training_curves()


def main():
    parser = argparse.ArgumentParser(description="ç«¹ç®€è •å˜æ‰©æ•£æ¨¡å‹è®­ç»ƒ - é€æ­¥æ¢å¤ç‰ˆ")

    # è·¯å¾„å’Œå°ºå¯¸å‚æ•°
    parser.add_argument('--dataset_root', type=str, required=True, help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„, éœ€åŒ…å« train å’Œ test å­ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='./outputs', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--image_size', type=int, nargs=2, default=[320, 32], help='å›¾åƒå°ºå¯¸ [H, W]')

    # è®­ç»ƒè¶…å‚æ•°
    parser.add_argument('--num_epochs', type=int, default=100, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=1e-4, help='å­¦ä¹ ç‡')
    parser.add_argument('--grad_clip', type=float, default=1.0, help='æ¢¯åº¦è£å‰ª')
    parser.add_argument('--weight_decay', type=float, default=1e-4, help='æƒé‡è¡°å‡')
    parser.add_argument('--num_workers', type=int, default=4, help='æ•°æ®åŠ è½½å™¨å·¥ä½œçº¿ç¨‹æ•°')

    # æ‰©æ•£å’Œç‰©ç†æ¨¡å‹å‚æ•°
    parser.add_argument('--T', type=int, default=100, help='æ‰©æ•£æ€»æ­¥æ•°')
    parser.add_argument('--control_nx', type=int, default=4, help='æ§åˆ¶ç‚¹Xæ–¹å‘æ•°é‡')
    parser.add_argument('--control_ny', type=int, default=32, help='æ§åˆ¶ç‚¹Yæ–¹å‘æ•°é‡')
    parser.add_argument('--fiber_elongation_factor', type=float, default=0.15, help='çº¤ç»´ä¼¸é•¿å› å­')
    parser.add_argument('--force_coupling_strength', type=float, default=0.3, help='åŠ›è€¦åˆå¼ºåº¦')
    parser.add_argument('--moisture_diffusion_coeff', type=float, default=0.15, help='æ°´åˆ†æ‰©æ•£ç³»æ•°')
    parser.add_argument('--inertia_factor', type=float, default=0.8, help='æƒ¯æ€§å› å­ (0-1)')

    # æ—¥å¿—å‚æ•°
    parser.add_argument('--log_interval', type=int, default=100, help='æ—¥å¿—è®°å½•é—´éš”(æ­¥)')

    args = parser.parse_args()
    train_model(args)


if __name__ == '__main__':
    main()
