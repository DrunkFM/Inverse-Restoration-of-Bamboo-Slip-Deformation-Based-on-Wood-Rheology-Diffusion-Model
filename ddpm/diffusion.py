import nbimporter
import torch
import torch.nn as nn
import torch.nn.functional as F

from forward import CreepDeformationEngine, CreepDiffusionTrainer as ForwardTrainer, extract
from Unet import ControlPointUNet


class CreepDiffusionTrainer(nn.Module):
    """
    ç‰©ç†è •å˜æ‰©æ•£è®­ç»ƒå™¨
    """

    def __init__(self, model, beta_1, beta_T, T,
                 image_size=(640, 24), control_grid_size=(32,4),
                 **physics_params):
        super().__init__()

        # ä½¿ç”¨forwardæ¨¡å—çš„è®­ç»ƒå™¨
        self.forward_trainer = ForwardTrainer(
            model=None,
            beta_1=beta_1,
            beta_T=beta_T,
            T=T,
            image_size=image_size,
            control_grid=control_grid_size
        )

        self.model = model  # ControlPointUNet
        self.physics_params = physics_params
        self.T = T

    def forward(self, x_0, displacement_weight=1.0, reconstruction_weight=0.5):
        """
        è®­ç»ƒå‰å‘è¿‡ç¨‹ (æ–°ç‰ˆï¼šè®¡ç®—ä½ç§»æŸå¤±å’Œé‡å»ºæŸå¤±)

        Args:
            x_0 (torch.Tensor): åŸå§‹æ¸…æ™°å›¾åƒ (N, C, H, W)
            displacement_weight (float): ä½ç§»æŸå¤±çš„æƒé‡
            reconstruction_weight (float): é‡å»ºæŸå¤±çš„æƒé‡

        Returns:
            torch.Tensor: åŠ æƒåçš„æ€»æŸå¤±
        """
        batch_size = x_0.shape[0]
        device = x_0.device

        # --- ç¬¬1æ­¥ï¼šç”Ÿæˆè®­ç»ƒæ ·æœ¬ ---
        # å’Œæ—§ç‰ˆä¸€æ ·ï¼Œéšæœºé€‰æ‹©æ—¶é—´æ­¥tï¼Œå¹¶ä½¿ç”¨ç‰©ç†å¼•æ“ç”Ÿæˆå˜å½¢åçš„å›¾åƒx_t
        # å’Œç”¨äºæ¢å¤çš„ç›®æ ‡é€†ä½ç§» target_displacements_batch
        t = torch.randint(1, self.T + 1, size=(batch_size,), device=device)
        x_t_batch = []
        target_displacements_batch = []
        for b in range(batch_size):
            self.forward_trainer.creep_engine.reset_control_state()
            # æ³¨æ„ï¼šè¿™é‡Œçš„ self.forward_trainer æ¥è‡ª forward.py
            x_t_single, _ = self.forward_trainer.forward_step_by_step(
                x_0[b:b + 1], t[b].item(), **self.physics_params
            )
            target_dx = -torch.from_numpy(self.forward_trainer.creep_engine.cumulative_displacement_x).float()
            target_dy = -torch.from_numpy(self.forward_trainer.creep_engine.cumulative_displacement_y).float()
            target_displacements = torch.stack([target_dx, target_dy], dim=1)
            x_t_batch.append(x_t_single)
            target_displacements_batch.append(target_displacements)

        x_t_batch = torch.cat(x_t_batch, dim=0)
        target_displacements_batch = torch.stack(target_displacements_batch, dim=0).to(device)

        # --- ç¬¬2æ­¥ï¼šæ¨¡å‹é¢„æµ‹ ---
        # U-Net æ ¹æ®å˜å½¢çš„å›¾åƒ x_t å’Œæ—¶é—´æ­¥ tï¼Œé¢„æµ‹æ¢å¤æ‰€éœ€çš„é€†ä½ç§»
        predicted_displacements = self.model(x_t_batch, t)

        # --- ç¬¬3æ­¥ï¼šè®¡ç®—ä½ç§»æŸå¤± (Displacement Loss) ---
        # è¿™æ˜¯æŸå¤±çš„ç¬¬ä¸€éƒ¨åˆ†ï¼šè®©æ¨¡å‹é¢„æµ‹çš„ä½ç§»å°½å¯èƒ½æ¥è¿‘ç‰©ç†å¼•æ“è®¡ç®—å‡ºçš„çœŸå®é€†ä½ç§»
        displacement_loss = F.mse_loss(predicted_displacements, target_displacements_batch)

        # --- ç¬¬4æ­¥ï¼šå®é™…æ¢å¤å›¾åƒå¹¶è®¡ç®—é‡å»ºæŸå¤± (Reconstruction Loss) ---
        # è¿™æ˜¯æŸå¤±çš„ç¬¬äºŒéƒ¨åˆ†ï¼šæƒ©ç½šé‚£äº›å¯¼è‡´å›¾åƒæ¨¡ç³Šæˆ–å¤±çœŸçš„æ¢å¤æ“ä½œ

        # a. ä½¿ç”¨æ¨¡å‹é¢„æµ‹çš„ä½ç§»ï¼Œé€šè¿‡å¯å¾®åˆ†çš„å‡½æ•°æ¥å®é™…â€œæ¢å¤â€å›¾åƒ
        dense_displacement_field = self.model._control_points_to_dense_field(
            predicted_displacements,
            target_img_shape=x_t_batch.shape
        )
        restored_image = self.model._apply_dense_displacement(x_t_batch, dense_displacement_field)

        # b. è®¡ç®—æ¢å¤å‡ºçš„å›¾åƒ restored_image å’Œ åŸå§‹æ¸…æ™°å›¾åƒ x_0 ä¹‹é—´çš„å·®åˆ«
        #    ä½¿ç”¨ L1 Loss å¯¹æ¨¡ç³Šå’Œå™ªç‚¹æ›´é²æ£’ï¼Œæ•ˆæœé€šå¸¸æ¯”MSEå¥½
        reconstruction_loss = F.l1_loss(restored_image, x_0)

        # --- ç¬¬5æ­¥ï¼šåŠ æƒåˆå¹¶æ€»æŸå¤± ---
        # å°†ä¸¤ä¸ªæŸå¤±æŒ‰æƒé‡ç›¸åŠ ï¼Œå¾—åˆ°æœ€ç»ˆçš„æ€»æŸå¤±
        total_loss = (displacement_weight * displacement_loss) + \
                     (reconstruction_weight * reconstruction_loss)

        # (å¯é€‰) æ‰“å°ä¸¤ä¸ªå­æŸå¤±çš„å€¼ï¼Œæ–¹ä¾¿æˆ‘ä»¬åœ¨è®­ç»ƒæ—¶ç›‘æ§å®ƒä»¬çš„ç›¸å¯¹å¤§å°
        if torch.rand(1) < 0.01:  # æ¯çº¦100æ¬¡è¿­ä»£æ‰“å°ä¸€æ¬¡
            print(f"\n[æŸå¤±ç›‘æ§] ä½ç§»æŸå¤±: {displacement_loss.item():.4f}, é‡å»ºæŸå¤±: {reconstruction_loss.item():.4f}")

        # è¿”å›æ€»æŸå¤±ï¼Œç”¨äºåå‘ä¼ æ’­
        return total_loss


class CreepDiffusionSampler(nn.Module):
    """
    ç‰©ç†è •å˜æ‰©æ•£é‡‡æ ·å™¨
    """

    def __init__(self, model, T=100):
        super().__init__()
        self.model = model  # ControlPointUNet
        self.T = T

        print(f"ğŸ”¬ CreepDiffusionSampler åˆå§‹åŒ–å®Œæˆ")

    def forward(self, x_T, show_progress=True):
        """
        é€æ­¥æ¢å¤ï¼šç›´æ¥è°ƒç”¨U-Netæ–¹æ³•ï¼Œé¿å…é‡å¤å®ç°
        """
        x_t = x_T.clone()
        restoration_history = [x_t.clone()]

        if show_progress:
            print(f"ğŸ”„ å¼€å§‹ç«¹ç®€æ¢å¤ ({self.T} æ­¥)")

        # é€æ­¥æ¢å¤
        for time_step in reversed(range(1, self.T + 1)):
            if show_progress and time_step % 20 == 0:
                print(f"   æ­¥éª¤: {self.T - time_step + 1}/{self.T}")

            # åˆ›å»ºæ—¶é—´æ­¥
            t = x_t.new_ones([x_T.shape[0]], dtype=torch.long) * time_step

            # ç›´æ¥è°ƒç”¨U-Netçš„ç°æœ‰æ–¹æ³•ï¼ˆé¿å…é‡å¤å®ç°ï¼‰
            x_t, _ = self.model.predict_and_apply_deformation(x_t, t)
            restoration_history.append(x_t.clone())

        x_0 = torch.clamp(x_t, 0, 1)

        if show_progress:
            print("âœ… æ¢å¤å®Œæˆï¼")

        return x_0, restoration_history

def create_trainer(model, T=100, **physics_params):
    """åˆ›å»ºè®­ç»ƒå™¨"""
    return CreepDiffusionTrainer(
        model=model, beta_1=1e-4, beta_T=0.02, T=T, **physics_params
    )


def create_sampler(model, T=100):
    """åˆ›å»ºé‡‡æ ·å™¨"""
    return CreepDiffusionSampler(model=model, T=T)


# æç®€è®­ç»ƒ/æ¨ç†æ¥å£
def train_step(trainer, batch, optimizer):
    """å•æ­¥è®­ç»ƒ"""
    optimizer.zero_grad()
    loss = trainer(batch).mean()
    loss.backward()
    optimizer.step()
    return loss.item()


def restore(sampler, deformed_bamboo, show_progress=True):
    """æ¢å¤ç«¹ç®€"""
    with torch.no_grad():
        return sampler(deformed_bamboo, show_progress)

def evaluate(original, restored):
    """è¯„ä¼°æ¢å¤è´¨é‡"""
    with torch.no_grad():
        mse = F.mse_loss(restored, original)
        psnr = -10 * torch.log10(mse + 1e-8)
    return {'mse': mse.item(), 'psnr': psnr.item()}
