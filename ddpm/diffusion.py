import nbimporter
import torch
import torch.nn as nn
import torch.nn.functional as F

from forward import CreepDeformationEngine, CreepDiffusionTrainer as ForwardTrainer, extract
from Unet import ControlPointUNet


class CreepDiffusionTrainer(nn.Module):
    """
    ç‰©ç†è •å˜æ‰©æ•£è®­ç»ƒå™¨
    """

    def __init__(self, model, beta_1, beta_T, T,
                 image_size=(640, 64), control_grid_size=(48, 6),
                 **physics_params):
        super().__init__()

        # ä½¿ç”¨forwardæ¨¡å—çš„è®­ç»ƒå™¨
        self.forward_trainer = ForwardTrainer(
            model=None,
            beta_1=beta_1,
            beta_T=beta_T,
            T=T,
            image_size=image_size
        )

        self.model = model  # ControlPointUNet
        self.physics_params = physics_params
        self.T = T

    def forward(self, x_0):
        """
        è®­ç»ƒå‰å‘è¿‡ç¨‹ï¼šå¤ç”¨forwardæ¨¡å—çš„é€»è¾‘
        """
        batch_size = x_0.shape[0]
        device = x_0.device

        # éšæœºé€‰æ‹©å˜å½¢ç¨‹åº¦
        t = torch.randint(1, self.forward_trainer.T + 1, size=(batch_size,), device=device)

        # æ‰¹é‡å¤„ç†ï¼šæ¯ä¸ªæ ·æœ¬ç‹¬ç«‹è¿›è¡Œç‰©ç†å˜å½¢
        x_t_batch = []
        target_displacements_batch = []

        for b in range(batch_size):
            # é‡ç½®å¹¶åº”ç”¨ç‰©ç†å˜å½¢ï¼ˆå¤ç”¨forwardæ¨¡å—æ–¹æ³•ï¼‰
            self.forward_trainer.creep_engine.reset_control_state()
            x_t_single, _ = self.forward_trainer.forward_step_by_step(
                x_0[b:b + 1], t[b].item(), **self.physics_params
            )

            # è·å–ç›®æ ‡é€†ä½ç§»
            target_dx = -torch.from_numpy(self.forward_trainer.creep_engine.cumulative_displacement_x).float()
            target_dy = -torch.from_numpy(self.forward_trainer.creep_engine.cumulative_displacement_y).float()
            target_displacements = torch.stack([target_dx, target_dy], dim=1)

            x_t_batch.append(x_t_single)
            target_displacements_batch.append(target_displacements)

        # ç»„è£…æ‰¹æ¬¡
        x_t_batch = torch.cat(x_t_batch, dim=0)
        target_displacements_batch = torch.stack(target_displacements_batch, dim=0).to(device)

        # U-Neté¢„æµ‹é€†ä½ç§»
        predicted_displacements = self.model(x_t_batch, t)

        # è®¡ç®—æŸå¤±
        loss = F.mse_loss(predicted_displacements, target_displacements_batch, reduction='none')

        return loss


class CreepDiffusionSampler(nn.Module):
    """
    ç‰©ç†è •å˜æ‰©æ•£é‡‡æ ·å™¨
    """

    def __init__(self, model, T=100):
        super().__init__()
        self.model = model  # ControlPointUNet
        self.T = T

        print(f"ğŸ”¬ CreepDiffusionSampler åˆå§‹åŒ–å®Œæˆ")

    def forward(self, x_T, show_progress=True):
        """
        é€æ­¥æ¢å¤ï¼šç›´æ¥è°ƒç”¨U-Netæ–¹æ³•ï¼Œé¿å…é‡å¤å®ç°
        """
        x_t = x_T.clone()
        restoration_history = [x_t.clone()]

        if show_progress:
            print(f"ğŸ”„ å¼€å§‹ç«¹ç®€æ¢å¤ ({self.T} æ­¥)")

        # é€æ­¥æ¢å¤
        for time_step in reversed(range(1, self.T + 1)):
            if show_progress and time_step % 20 == 0:
                print(f"   æ­¥éª¤: {self.T - time_step + 1}/{self.T}")

            # åˆ›å»ºæ—¶é—´æ­¥
            t = x_t.new_ones([x_T.shape[0]], dtype=torch.long) * time_step

            # ç›´æ¥è°ƒç”¨U-Netçš„ç°æœ‰æ–¹æ³•ï¼ˆé¿å…é‡å¤å®ç°ï¼‰
            x_t, _ = self.model.predict_and_apply_deformation(x_t, t)
            restoration_history.append(x_t.clone())

        x_0 = torch.clamp(x_t, 0, 1)

        if show_progress:
            print("âœ… æ¢å¤å®Œæˆï¼")

        return x_0, restoration_history

def create_trainer(model, T=100, **physics_params):
    """åˆ›å»ºè®­ç»ƒå™¨"""
    return CreepDiffusionTrainer(
        model=model, beta_1=1e-4, beta_T=0.02, T=T, **physics_params
    )


def create_sampler(model, T=100):
    """åˆ›å»ºé‡‡æ ·å™¨"""
    return CreepDiffusionSampler(model=model, T=T)


# æç®€è®­ç»ƒ/æ¨ç†æ¥å£
def train_step(trainer, batch, optimizer):
    """å•æ­¥è®­ç»ƒ"""
    optimizer.zero_grad()
    loss = trainer(batch).mean()
    loss.backward()
    optimizer.step()
    return loss.item()


def restore(sampler, deformed_bamboo, show_progress=True):
    """æ¢å¤ç«¹ç®€"""
    with torch.no_grad():
        return sampler(deformed_bamboo, show_progress)

def evaluate(original, restored):
    """è¯„ä¼°æ¢å¤è´¨é‡"""
    with torch.no_grad():
        mse = F.mse_loss(restored, original)
        psnr = -10 * torch.log10(mse + 1e-8)
    return {'mse': mse.item(), 'psnr': psnr.item()}